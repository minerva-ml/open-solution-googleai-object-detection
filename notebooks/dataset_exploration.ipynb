{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "DIRPATH = '/mnt/ml-team/open-images-v4/bounding-boxes'\n",
    "DIRPATH_COMPETITION = '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/ml-team/open-images-v4/bounding-boxes/boxes',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/image-labels',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/imageIds',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/metadata',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/validation',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/train',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/test',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/test_challenge_2018']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('{}/*'.format(DIRPATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/ml-team/open-images-v4/bounding-boxes/boxes/train-annotations-bbox.csv',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/boxes/validation-annotations-bbox.csv',\n",
       " '/mnt/ml-team/open-images-v4/bounding-boxes/boxes/test-annotations-bbox.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('{}/boxes/*'.format(DIRPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boxes = pd.read_csv(os.path.join(DIRPATH,'boxes','train-annotations-bbox.csv'))\n",
    "train_boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_boxes = pd.read_csv(os.path.join(DIRPATH,'boxes','validation-annotations-bbox.csv'))\n",
    "valid_boxes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "Let's look at the data sources in train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boxes['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_boxes['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different sources used in train and valid, which could affect how the labels were collected\n",
    "\n",
    "## Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boxes['Confidence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_boxes['Confidence'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both in train and valid confidence on every bbox of every image is `1`.\n",
    "\n",
    "Why have this flag then?\n",
    "\n",
    "## LabelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boxes['LabelName'].nunique(), valid_boxes['LabelName'].nunique(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boxes['LabelName'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`559` labels that have from `4` to `1438128` examples in the train set. \n",
    "\n",
    "Sounds like a lot of fun :)\n",
    "# image-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/image-labels/*'.format(DIRPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_labels = pd.read_csv(os.path.join(DIRPATH,'image-labels','train-annotations-human-imagelabels-boxable.csv'))\n",
    "train_image_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_labels = pd.read_csv(os.path.join(DIRPATH,'image-labels','validation-annotations-human-imagelabels-boxable.csv'))\n",
    "valid_image_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_labels['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_labels['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_labels['Confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_labels['Confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this looks a bit more reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imageIds\n",
    "\n",
    "Just some info on the origin of data, authors, licence and stuff like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/imageIds/*'.format(DIRPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imageIds = pd.read_csv(os.path.join(DIRPATH,'imageIds','train-images-boxable-with-rotation.csv'))\n",
    "train_imageIds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_imageIds = pd.read_csv(os.path.join(DIRPATH,'imageIds','validation-images-with-rotation.csv'))\n",
    "valid_imageIds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metadata\n",
    "\n",
    "This is just label-code to label-name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/metadata/*'.format(DIRPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(DIRPATH,'metadata','class-descriptions-boxable.csv'))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, validation, test, test_challenge\n",
    "\n",
    "Those are just folders with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/test_challenge_2018/*'.format(DIRPATH))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/sample_submission.csv.zip',\n",
       " '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/sample_submission.csv',\n",
       " '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/annotations',\n",
       " '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/imageIds',\n",
       " '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/metadata']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('{}/*'.format(DIRPATH_COMPETITION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/annotations/challenge-2018-train-annotations-bbox.csv',\n",
       " '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/annotations/challenge-2018-train-annotations-human-imagelabels.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('{}/annotations/*'.format(DIRPATH_COMPETITION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Source</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>XMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMin</th>\n",
       "      <th>YMax</th>\n",
       "      <th>IsOccluded</th>\n",
       "      <th>IsTruncated</th>\n",
       "      <th>IsGroupOf</th>\n",
       "      <th>IsDepiction</th>\n",
       "      <th>IsInside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d6dec80235b6fea</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/09j5n</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.645892</td>\n",
       "      <td>0.673277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d6dec80235b6fea</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/09j5n</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.628895</td>\n",
       "      <td>0.661945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8d6dec80235b6fea</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/09j5n</td>\n",
       "      <td>1</td>\n",
       "      <td>0.843125</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.619452</td>\n",
       "      <td>0.645892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8d6dec80235b6fea</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/09j5n</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.891875</td>\n",
       "      <td>0.597734</td>\n",
       "      <td>0.625118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8d6dec80235b6fea</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/09j5n</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895625</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.625118</td>\n",
       "      <td>0.656280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  Source LabelName  Confidence      XMin      XMax  \\\n",
       "0  8d6dec80235b6fea  xclick  /m/09j5n           1  0.760000  0.778125   \n",
       "1  8d6dec80235b6fea  xclick  /m/09j5n           1  0.817500  0.831875   \n",
       "2  8d6dec80235b6fea  xclick  /m/09j5n           1  0.843125  0.870000   \n",
       "3  8d6dec80235b6fea  xclick  /m/09j5n           1  0.867500  0.891875   \n",
       "4  8d6dec80235b6fea  xclick  /m/09j5n           1  0.895625  0.911250   \n",
       "\n",
       "       YMin      YMax  IsOccluded  IsTruncated  IsGroupOf  IsDepiction  \\\n",
       "0  0.645892  0.673277           0            0          0            0   \n",
       "1  0.628895  0.661945           0            0          0            0   \n",
       "2  0.619452  0.645892           0            0          0            0   \n",
       "3  0.597734  0.625118           0            0          0            0   \n",
       "4  0.625118  0.656280           0            0          0            0   \n",
       "\n",
       "   IsInside  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_bbox = pd.read_csv(os.path.join(DIRPATH_COMPETITION,'annotations','challenge-2018-train-annotations-bbox.csv'))\n",
    "annotations_bbox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_bbox['Confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_label = pd.read_csv(os.path.join(DIRPATH_COMPETITION,'annotations','challenge-2018-train-annotations-human-imagelabels.csv'))\n",
    "annotations_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imageIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/imageIds/*'.format(DIRPATH_COMPETITION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageIds = pd.read_csv(os.path.join(DIRPATH_COMPETITION,'imageIds','train-images-boxable-with-rotation.csv'))\n",
    "imageIds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/metadata/*'.format(DIRPATH_COMPETITION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions = pd.read_csv(os.path.join(DIRPATH_COMPETITION,'metadata','challenge-2018-class-descriptions-500.csv'),header=None)\n",
    "class_descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy = pd.read_json(os.path.join(DIRPATH_COMPETITION,'metadata','bbox_labels_500_hierarchy.json'))\n",
    "hierarchy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = pd.read_csv(os.path.join(DIRPATH_COMPETITION,'metadata','challenge-2018-image-ids-valset-od.csv'))\n",
    "val_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(imageIds['ImageID']) & set(val_ids['ImageID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('{}/*'.format(os.path.join(DIRPATH,'test_challenge_2018')))[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_py3",
   "language": "python",
   "name": "dl_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
