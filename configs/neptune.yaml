project: neptune-ml/Google-Ai-Object-Detection-Challenge
#project: USERNAME/googleai-object-detection

name: Google AI object detection
tags: [solution-1]

metric:
  channel: 'MAP'
  goal: maximize

#Comment out if not in Cloud Environment
pip-requirements-file: requirements.txt # Comment out if Local execution

exclude:
  - .git
  - .idea
  - .ipynb_checkpoints
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - notebooks
  - src/object_detection

parameters:
# Data Paths
  train_imgs_dir: /public/datasets/open-images-dataset-v4/bounding-boxes/train
  test_imgs_dir: /public/datasets/open-images-dataset-v4/bounding-boxes/test_challenge_2018
  annotations_filepath: /public/challenges/google-ai-open-images-object-detection-track/annotations/challenge-2018-train-annotations-bbox.csv
  annotations_human_labels_filepath: /public/challenges/google-ai-open-images-object-detection-track/annotations/challenge-2018-train-annotations-human-imagelabels.csv
  bbox_hierarchy_filepath: /public/challenges/google-ai-open-images-object-detection-track/metadata/bbox_labels_500_hierarchy.json
  class_mappings_filepath: /public/challenges/google-ai-open-images-object-detection-track/metadata/challenge-2018-class-descriptions-500.csv
  valid_ids_filepath: /public/challenges/google-ai-open-images-object-detection-track/metadata/challenge-2018-image-ids-valset-od.csv
  sample_submission: /public/challenges/google-ai-open-images-object-detection-track/sample_submission.csv
  experiment_dir:  /output/experiment

  # Execution
  clean_experiment_directory_before_training: 1
  num_workers: 4
  num_threads: 4
  load_in_memory: 0
  pin_memory: 1
  default_valid_ids: 1
  loader_mode: resize
  stream_mode: 0
  validate_with_map: 1
  small_annotations_size: 20
  kaggle_message: 'solution-1'

# General parameters
  image_h: 512
  image_w: 512
  image_channels: 3
  pad_method: 'resize'

# Retina parameters (multi-output)
  encoder_depth: 50
  num_classes: 10
  pretrained_encoder: 1
  pi: 0.01
  aspect_ratios: '[1/2., 1/1., 2/1.]'
  scale_ratios: '[1., pow(2,1/3.), pow(2,2/3.)]'

# Training schedule
  epochs_nr: 10
  batch_size_train: 2
  batch_size_inference: 2
  lr: 0.0005
  momentum: 0.9
  gamma: 1.0
  patience: 30
  lr_factor: 0.3
  lr_patience: 30
  training_sample_size: 50000
  validation_sample_size: 10000

# Regularization
  use_batch_norm: 1
  l2_reg_conv: 0.0001
  l2_reg_dense: 0.0
  dropout_conv: 0.1
  dropout_dense: 0.0
